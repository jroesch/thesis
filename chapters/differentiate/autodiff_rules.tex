\begin{figure}
    % NOTE: We need to explain that `\revv{f}' is the registere gradient of `f'.
    \centering
    $\begin{array}{lll}
      % Tensor Type
      \textsf{ADType}\left(\kwd{Tensor } t\right) &=& \rTuple{t}{\kwd{Ref[}t\kwd{]}} \\[0.5em]
      % Tuple Type
      \textsf{ADType}\left(\rTuple{t_0}{\cdots}{t_n}\right) &=& \rTuple{\textsf{ADType}(t_0)}{\cdots}{\textsf{ADType}(t_n)} \\[0.5em]
      % Variable
      \textsf{ADTerm}\left(\kwd{Var } x\right) &=& x \\[0.5em]
      % Reference
      \textsf{ADTerm}\left(\kwd{Ref } e\right) &=& \kwd{ref(}\textsf{ADTerm}(e)\kwd{)} \\[0.5em]
      % Literal
      \textsf{ADTerm}\left(\kwd{Lit } l\right) &=& \rTuple{l}{\kwd{ref(}\texttt{0}\kwd{)}} \\[0.5em]
      % Tuple
      \textsf{ADTerm}\left(\rTuple{e_0}{\cdots}{e_n}\right) &=& \rTuple{\textsf{ADTerm}(e_0)}{\cdots}{\textsf{ADTerm}(e_n)} \\[0.5em]
      % Match
      \textsf{ADTerm}(\kwd{match (} e\kwd{) \textbraceleft} &=& \kwd{match (}\textsf{ADTerm}(e)\kwd{)} \kwd{ \textbraceleft} \\
      \quad \kwd{| } p_0 \rightarrow e_0 & & \quad \kwd{| } p_0 \kwd{ $\rightarrow$ } \textsf{ADTerm}(e_0) \\
      \quad \vdots & & \quad \vdots \\
      \quad \kwd{| } p_n \rightarrow e_n & & \quad \kwd{| } p_n \kwd{ $\rightarrow$ } \textsf{ADTerm}(e_n)\\
      \kwd{\textbraceright}) & & \kwd{\textbraceright}
      \\[0.5em]
      % Function
      \textsf{ADTerm}(\kwd{fn (} &=& \kwd{fn (} \\
      \quad \rParam{x_0}{t_0}\kwd{,} & & \quad \rParam{x_0}{\textsf{ADType}(t_0)}\kwd{,} \\
      \quad \vdots\kwd{,} & & \quad \vdots\kwd{,} \\
      \quad \rParam{x_n}{t_n} \kwd{)} & & \quad \rParam{x_n}{\textsf{ADType}(t_n)} \kwd{)} \\
      \quad \quad \kwd{$\rightarrow$ } t_{\text{ret}} & & \quad \kwd{$\rightarrow$ } \textsf{ADType}(t_{\text{ret}}) \\
      \kwd{\textbraceleft }\,\,\, e \kwd{ \textbraceright}) & & \kwd{\textbraceleft }\,\,\, \textsf{ADTerm}(e) \kwd{ \textbraceright}\\
      \\[0.5em]
    % \end{array}$
    % $\begin{array}{l}
      % Call
      \textsf{ADTerm}\left(f\rTuple{e_0}{\cdots}{e_n}\right) \ \ \  = \\
      \quad \rLet{\revv{e_0}}{}{\textsf{ADTerm($e_0$)}}{} \\
      \quad \vdots \\
      \quad \rLet{\revv{e_n}}{}{\textsf{ADTerm($e_n$)}}{} \\
      \quad \rLet{v}{}{f\rTuple{\revv{e_0}\kwd{.}\texttt{0}}{\cdots}{\revv{e_n}\kwd{.}\texttt{0}}}{} \\
      \quad \rLet{\bper{v}}{}{\kwd{ref(}\texttt{0}\kwd{)}}{} \\
      \quad \kwd{let } \delta \kwd{ = fn () \textbraceleft} \\
      \quad \quad \rLet{\rTuple{\sens{e_0}}{\cdots}{\sens{e_n}}}{}{\\ \quad \quad \quad \revv{f}\rTuple{v}{\kwd{!}\bper{v}}{\kwd{!}\revv{e_0}\kwd{.}\texttt{0}}{\cdots}{\kwd{!}\revv{e_n}\kwd{.}\texttt{0}}}{} \\
      \quad \quad \revv{e_0}\kwd{.}\texttt{1} \kwd{ $\pluseq$ } \sens{e_0} \kwd{;} \\
      \quad \quad \vdots \\
      \quad \quad \revv{e_n}\kwd{.}\texttt{1} \kwd{ $\pluseq$ } \sens{e_n} \kwd{;} \\
      \quad \quad \kwd{()} \\
      \quad \kwd{\textbraceright;} \\
      \quad \Delta \kwd{ $\coloneqq$ } \kwd{!}\Delta \kwd{ $\circ$ } \delta \kwd{;} \\
  %    \quad \Delta \kwd{ := } \kwd{!}\Delta \kwd{ $\circ$ } \delta \kwd{;} \\
      \quad \rTuple{v}{\bper{v}}
    \end{array}$
    \caption{
      Transformation Rules for Automatic Differentiation in Relay.
      The most interesting case is for function calls.
      The backpropagator $\Delta$ is initialized to \kwd{ref(fn() \textbraceleft\ ()
        \textbraceright)} at the top level of each \textsf{ADTerm} call.
      Successive update closures $\delta$ are then composed with $\Delta$ to
        form a chain.
      Syntactic sugar is used for some constructs which are not available as
        primitives in Relay.
    }
    \label{fig:autodiff_rules}
  \end{figure}
